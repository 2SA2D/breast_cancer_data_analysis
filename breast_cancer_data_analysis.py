# -*- coding: utf-8 -*-
"""breast-cancer-data-analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17bTzhJispAPQnicS9OXUBjfW_1mA7LTo
"""

# Accessing to Google Drive
from google.colab import drive
drive.mount('/content/drive')

#Importlibraries
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.neighbors import NearestCentroid, KNeighborsClassifier
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix, classification_report
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from matplotlib.colors import ListedColormap

# Reading the dataset
df = pd.read_csv('/content/drive/MyDrive/COMP4603/HW1/breast-cancer-wisconsin.csv',header = None)

#Display the data
df.head()

#Check if there is a null value
df.isnull().sum()

#Change the missing attribute value that denoted by "?" to "NaN" value
columns_updated = {0:{"?":np.nan}, 1:{"?":np.nan},2:{"?":np.nan},3:{"?":np.nan},4:{"?":np.nan},5:{"?":np.nan},6:{"?":np.nan},7:{"?":np.nan},8:{"?":np.nan},9:{"?":np.nan},10:{"?":np.nan}}
df1 = df.replace(columns_updated)
df1

#Check another time if there is a null value
df1.isnull().sum()

# deleting the corresponding rows
df2 = df1.dropna()
df2

# change the columns name
df2.columns = ["Sample code number","Clump Thickness","Uniformity of Cell Size","Uniformity of Cell Shape","Marginal Adhesion","Single Epithelial Cell Size","Bare Nuclei","Bland Chromatin","Normal Nucleoli","Mitoses","Class"]

df2

sns.pairplot(df2,size=2)

# Extract the features into a matrix X 

X = df2.iloc[:,:-1].values
X

#labels (last column in the dataset) into a vector y.
y = df2.iloc[:,-1].values
y

#Convert the labels to 0, for benign, and 1 for malignant.
columns_updated = {'Class':{2:0, 4:1}}
df3 = df2.replace(columns_updated)
df3

#Split the dataset into training and test sets.
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5)
print(X_train.shape, X_test.shape)

#Train a K-NN classifier with the number of neighbors k=1.
nn = KNeighborsClassifier(n_neighbors=1)
nn.fit(X_train, y_train)

#Evaluate the trained classifier on the test set.
y_pred = nn.predict(X_test)
accuracy_KNN = accuracy_score(y_pred, y_test)
print(f"Accuracy on the test set = {accuracy_KNN:.2f}")

#Report classifier performance in terms of classifier accuracy on the test set.
class_names = ['c0','c1']
report = classification_report(y_pred, y_test, target_names = class_names)
print(report)

"""**10. Apply feature scaling (using minmax and z-score scalers**"""

# using MinMaxScaler
scaler_mm = MinMaxScaler()
X_train_mm = scaler_mm.fit_transform(X_train)
X_test_mm = scaler_mm.transform(X_test)

# using z-score scaler
scaler_z = StandardScaler()
X_train_z = scaler_z.fit_transform(X_train)
X_test_z = scaler_z.transform(X_test)

# repeat the 7,8 and 9 steps
n = KNeighborsClassifier(n_neighbors=1)
n.fit(X_train_mm, y_train)

y_pred_mm = n.predict(X_test_mm)
accuracy_KNN = accuracy_score(y_pred_mm, y_test)
print(f"Accuracy on the test set = {accuracy_KNN:.2f}")

#Report classifier performance in terms of classifier accuracy on the test set.
class_names = ['c0','c1']
report = classification_report(y_pred_mm, y_test, target_names = class_names)
print(report)

_n = KNeighborsClassifier(n_neighbors=1)
_n.fit(X_train_z, y_train)

y_pred_z = _n.predict(X_test_z)
accuracy_KNN = accuracy_score(y_pred_z, y_test)
print(f"Accuracy on the test set = {accuracy_KNN:.2f}")

#Report classifier performance in terms of classifier accuracy on the test set.
class_names = ['c0','c1']
report = classification_report(y_pred_z, y_test, target_names = class_names)
print(report)

#Apply dimensionality reduction using feature selection. Keep only 2 features.
_nn=KNeighborsClassifier(n_neighbors=1)
sfs = SequentialFeatureSelector(_nn, n_features_to_select=2, direction = 'forward') 
sfs.fit(X_train, y_train)
X_train_reduced = sfs.transform(X_train)
X_test_reduced = sfs.transform(X_test)

# plot the scatter of the X_train_reduced
plt.figure(figsize=(5,5))
df3.plot(kind="scatter",x=0,y=1)
plt.show()

#Redo 7), 8) and 9). for sfs
_nn.fit(X_train_reduced, y_train)
y_pred_sfs = _nn.predict(X_test_reduced)
accuracy_KNN = accuracy_score(y_pred_sfs, y_test)
print(f"Accuracy on the test set = {accuracy_KNN:.2f}")

#Report classifier performance in terms of classifier accuracy on the test set.
class_names = ['c0','c1']
report = classification_report(y_pred_sfs, y_test, target_names = class_names)
print(report)

sbs = SequentialFeatureSelector(_nn, n_features_to_select=2, direction = 'backward') 
sbs.fit(X_train_mm, y_train)
X_train_reduced = sbs.transform(X_train_mm)
X_test_reduced = sbs.transform(X_test_mm)

n.fit(X_train_reduced, y_train)
y_pred_sbs = n.predict(X_test_reduced)
accuracy_KNN = accuracy_score(y_pred_sbs, y_test)
print(f"Accuracy on the test set = {accuracy_KNN:.2f}")

#Report classifier performance in terms of classifier accuracy on the test set.
class_names = ['c0','c1']
report = classification_report(y_pred_sbs, y_test, target_names = class_names)
print(report)